{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ilans\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ilans\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ilans\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HotelReviews</th>\n",
       "      <th>Labels</th>\n",
       "      <th>review_without_stopwords_x</th>\n",
       "      <th>review_without_stopwords_y</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we stayed at the schicago hilton for 4 days an...</td>\n",
       "      <td>deceptive</td>\n",
       "      <td>stayed schicago hilton 4 days 3 nights confere...</td>\n",
       "      <td>[(stayed, VBN), (schicago, JJ), (hilton, NN), ...</td>\n",
       "      <td>stayed/VBN schicago/JJ hilton/NN 4/CD days/NNS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hotel is located 1/2 mile from the train stati...</td>\n",
       "      <td>deceptive</td>\n",
       "      <td>hotel located 1/2 mile train station quite hik...</td>\n",
       "      <td>[(hotel, NN), (located, VBD), (1/2, CD), (mile...</td>\n",
       "      <td>hotel/NN located/VBD 1/2/CD mile/NN train/NN s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i made my reservation at the hilton chicago be...</td>\n",
       "      <td>deceptive</td>\n",
       "      <td>made reservation hilton chicago believing goin...</td>\n",
       "      <td>[(made, VBN), (reservation, NN), (hilton, NN),...</td>\n",
       "      <td>made/VBN reservation/NN hilton/NN chicago/NN b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when most people think hilton, they think luxu...</td>\n",
       "      <td>deceptive</td>\n",
       "      <td>people think hilton, think luxury. know did. w...</td>\n",
       "      <td>[(people, NNS), (think, VBP), (hilton, NN), (t...</td>\n",
       "      <td>people/NNS think/VBP hilton/NN think/VBP luxur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my husband and i recently stayed stayed at the...</td>\n",
       "      <td>deceptive</td>\n",
       "      <td>husband recently stayed stayed hilton chicago ...</td>\n",
       "      <td>[(husband, NN), (recently, RB), (stayed, VBD),...</td>\n",
       "      <td>husband/NN recently/RB stayed/VBD stayed/JJ hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        HotelReviews     Labels  \\\n",
       "0  we stayed at the schicago hilton for 4 days an...  deceptive   \n",
       "1  hotel is located 1/2 mile from the train stati...  deceptive   \n",
       "2  i made my reservation at the hilton chicago be...  deceptive   \n",
       "3  when most people think hilton, they think luxu...  deceptive   \n",
       "4  my husband and i recently stayed stayed at the...  deceptive   \n",
       "\n",
       "                          review_without_stopwords_x  \\\n",
       "0  stayed schicago hilton 4 days 3 nights confere...   \n",
       "1  hotel located 1/2 mile train station quite hik...   \n",
       "2  made reservation hilton chicago believing goin...   \n",
       "3  people think hilton, think luxury. know did. w...   \n",
       "4  husband recently stayed stayed hilton chicago ...   \n",
       "\n",
       "                          review_without_stopwords_y  \\\n",
       "0  [(stayed, VBN), (schicago, JJ), (hilton, NN), ...   \n",
       "1  [(hotel, NN), (located, VBD), (1/2, CD), (mile...   \n",
       "2  [(made, VBN), (reservation, NN), (hilton, NN),...   \n",
       "3  [(people, NNS), (think, VBP), (hilton, NN), (t...   \n",
       "4  [(husband, NN), (recently, RB), (stayed, VBD),...   \n",
       "\n",
       "                                                 pos  \n",
       "0  stayed/VBN schicago/JJ hilton/NN 4/CD days/NNS...  \n",
       "1  hotel/NN located/VBD 1/2/CD mile/NN train/NN s...  \n",
       "2  made/VBN reservation/NN hilton/NN chicago/NN b...  \n",
       "3  people/NNS think/VBP hilton/NN think/VBP luxur...  \n",
       "4  husband/NN recently/RB stayed/VBD stayed/JJ hi...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag,pos_tag_sents\n",
    "import regex as re\n",
    "import operator\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "path = r'\\Users\\ilans\\Documents\\Studies\\Semester 5\\Final Project\\op_spam_v1.4'\n",
    "\n",
    "label = []\n",
    "\n",
    "configfiles = [os.path.join(subdir,f)\n",
    "for subdir, dirs, files in os.walk(path)\n",
    "    for f in fnmatch.filter(files, '*.txt')]\n",
    "\n",
    "for f in configfiles:\n",
    "    c = re.search('(trut|deceptiv)\\w',f)\n",
    "    label.append(c.group())\n",
    "\n",
    "labels = pd.DataFrame(label, columns = ['Labels'])\n",
    "\n",
    "review = []\n",
    "directory =os.path.join(r'\\Users\\ilans\\Documents\\Studies\\Semester 5\\Final Project\\op_spam_v1.4')\n",
    "for subdir,dirs ,files in os.walk(directory):\n",
    "   # print (subdir)\n",
    "    for file in files:\n",
    "        if fnmatch.filter(files, '*.txt'):\n",
    "            f=open(os.path.join(subdir, file),'r')\n",
    "            a = f.read()\n",
    "            review.append(a)\n",
    "            \n",
    "reviews = pd.DataFrame(review, columns = ['HotelReviews'])\n",
    "result = pd.merge(reviews, labels,right_index=True,left_index = True)\n",
    "\n",
    "\n",
    "result['HotelReviews'] = result['HotelReviews'].map(lambda x: x.lower())\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "result['review_without_stopwords'] = result['HotelReviews'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "result.head().append(result.tail())\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "def pos(review_without_stopwords):\n",
    "    return TextBlob(review_without_stopwords).tags\n",
    "os = result.review_without_stopwords.apply(pos)\n",
    "os1 = pd.DataFrame(os)\n",
    "os1['pos'] = os1['review_without_stopwords'].map(lambda x:\" \".join([\"/\".join(x) for x in x ]) )\n",
    "result = result = pd.merge(result, os1,right_index=True,left_index = True)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "review_train, review_test, label_train, label_test = train_test_split(result['pos'],result['Labels'], test_size=0.2,random_state=5)\n",
    "\n",
    "tf_vect = TfidfVectorizer(lowercase = True, use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "\n",
    "X_train_tf = tf_vect.fit_transform(review_train)\n",
    "X_test_tf = tf_vect.transform(review_test)\n",
    "\n",
    "def svc_param_selection(X, y, nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel='linear'), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search.best_params_\n",
    "svc_param_selection(X_train_tf,label_train,5)\n",
    "clf = svm.SVC(C=10,gamma=0.001,kernel='linear')\n",
    "clf.fit(X_train_tf,label_train)\n",
    "pred = clf.predict(X_test_tf)\n",
    "with open('vectorizer.pickle', 'wb') as fin:\n",
    "    pickle.dump(tf_vect, fin)\n",
    "with open('mlmodel.pickle','wb') as f:\n",
    "    pickle.dump(clf,f)\n",
    "    \n",
    "pkl = open('mlmodel.pickle', 'rb')\n",
    "clf = pickle.load(pkl)   \n",
    "vec = open('vectorizer.pickle', 'rb')\n",
    "tf_vect = pickle.load(vec)\n",
    "X_test_tf = tf_vect.transform(review_test)\n",
    "pred = clf.predict(X_test_tf)\n",
    "\n",
    "print(metrics.accuracy_score(label_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stayed', 'VBN'),\n",
       " ('schicago', 'JJ'),\n",
       " ('hilton', 'NN'),\n",
       " ('4', 'CD'),\n",
       " ('days', 'NNS'),\n",
       " ('3', 'CD'),\n",
       " ('nights', 'NNS'),\n",
       " ('conference', 'NN'),\n",
       " ('say', 'NN'),\n",
       " ('normally', 'RB'),\n",
       " ('easy', 'JJ'),\n",
       " ('going', 'VBG'),\n",
       " ('amenities', 'NNS'),\n",
       " ('cleanliness', 'NN'),\n",
       " ('like', 'IN'),\n",
       " ('however', 'RB'),\n",
       " ('experience', 'IN'),\n",
       " ('hilton', 'NN'),\n",
       " ('awful', 'IN'),\n",
       " ('taking', 'VBG'),\n",
       " ('time', 'NN'),\n",
       " ('actually', 'RB'),\n",
       " ('write', 'JJ'),\n",
       " ('review', 'NN'),\n",
       " ('truly', 'RB'),\n",
       " ('stay', 'JJ'),\n",
       " ('hotel', 'NN'),\n",
       " ('arrived', 'JJ'),\n",
       " ('room', 'NN'),\n",
       " ('clear', 'JJ'),\n",
       " ('carpet', 'NN'),\n",
       " ('vacuumed', 'VBD'),\n",
       " ('figuered', 'VBN'),\n",
       " ('okay', 'NN'),\n",
       " ('carpet', 'NN'),\n",
       " ('saw', 'NN'),\n",
       " ('bathroom', 'NN'),\n",
       " ('although', 'IN'),\n",
       " ('bathroom', 'JJ'),\n",
       " ('superficial', 'JJ'),\n",
       " ('indicators', 'NNS'),\n",
       " ('housekeeping', 'VBG'),\n",
       " ('recently', 'RB'),\n",
       " ('cleaned', 'VBN'),\n",
       " ('i.e.', 'FW'),\n",
       " ('paper', 'NN'),\n",
       " ('band', 'NN'),\n",
       " ('across', 'IN'),\n",
       " ('toilet', 'NN'),\n",
       " ('paper', 'NN'),\n",
       " ('caps', 'NNS'),\n",
       " ('drinking', 'VBG'),\n",
       " ('glasses', 'NNS'),\n",
       " ('etc.', 'FW'),\n",
       " ('clear', 'JJ'),\n",
       " ('actual', 'JJ'),\n",
       " ('cleaning', 'NN'),\n",
       " ('took', 'VBD'),\n",
       " ('place', 'NN'),\n",
       " ('spot', 'NN'),\n",
       " ('probably', 'RB'),\n",
       " ('urine', 'NN'),\n",
       " ('toilet', 'NN'),\n",
       " ('seat', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('kid', 'FW'),\n",
       " ('not', 'RB'),\n",
       " ('remnants', 'NNS'),\n",
       " ('lip-smudge', 'JJ'),\n",
       " ('glass', 'NN'),\n",
       " ('know', 'JJ'),\n",
       " ('people', 'NNS'),\n",
       " ('worked', 'VBD'),\n",
       " ('many', 'JJ'),\n",
       " ('years', 'NNS'),\n",
       " ('hotel', 'VBP'),\n",
       " ('industry', 'NN'),\n",
       " ('always', 'RB'),\n",
       " ('warned', 'VBD'),\n",
       " ('lazy', 'JJ'),\n",
       " ('housekeeping', 'VBG'),\n",
       " ('make', 'VBP'),\n",
       " ('things', 'NNS'),\n",
       " ('appear', 'JJ'),\n",
       " ('clean', 'JJ'),\n",
       " ('fact', 'NN'),\n",
       " ('make', 'VB'),\n",
       " ('effort', 'NN'),\n",
       " ('keep', 'VB'),\n",
       " ('things', 'NNS'),\n",
       " ('sanitary', 'JJ'),\n",
       " ('well', 'RB'),\n",
       " ('hilton', 'NN'),\n",
       " ('proof', 'NN'),\n",
       " ('called', 'VBN'),\n",
       " ('downstairs', 'NNS'),\n",
       " ('complained', 'VBD'),\n",
       " ('sent', 'VBD'),\n",
       " ('chambermaid', 'NN'),\n",
       " ('hours', 'NNS'),\n",
       " ('later', 'RB'),\n",
       " ('frankly', 'RB'),\n",
       " ('found', 'VBD'),\n",
       " ('room', 'NN'),\n",
       " ('disgusting', 'NN'),\n",
       " ('hotel', 'NN'),\n",
       " ('itself', 'PRP'),\n",
       " ('outside', 'RB'),\n",
       " ('rooms', 'NNS'),\n",
       " ('cavernous', 'JJ'),\n",
       " ('unwelcoming', 'NN'),\n",
       " ('awful', 'JJ'),\n",
       " ('echo', 'JJ'),\n",
       " ('lobby', 'NN'),\n",
       " ('area', 'NN'),\n",
       " ('created', 'VBD'),\n",
       " ('migraine-inducing', 'JJ'),\n",
       " ('din', 'NN'),\n",
       " ('rarely', 'RB'),\n",
       " ('eager', 'JJ'),\n",
       " ('leave', 'VBP'),\n",
       " ('place', 'NN'),\n",
       " ('this', 'DT'),\n",
       " ('got', 'VBD'),\n",
       " ('home', 'NN'),\n",
       " ('washed', 'VBD'),\n",
       " ('clothes', 'NNS'),\n",
       " ('whether', 'IN'),\n",
       " ('worn', 'NN'),\n",
       " ('not', 'RB'),\n",
       " ('skeeviness', 'JJ'),\n",
       " ('accomodations', 'NNS'),\n",
       " ('please', 'NN'),\n",
       " ('favor', 'NN'),\n",
       " ('stay', 'JJ'),\n",
       " ('clean', 'JJ'),\n",
       " ('hotel', 'NN')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['review_without_stopwords_y'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128  16]\n",
      " [ 16 160]]\n"
     ]
    }
   ],
   "source": [
    "print (confusion_matrix(label_test, pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   deceptive       0.89      0.89      0.89       144\n",
      "       truth       0.91      0.91      0.91       176\n",
      "\n",
      "    accuracy                           0.90       320\n",
      "   macro avg       0.90      0.90      0.90       320\n",
      "weighted avg       0.90      0.90      0.90       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(label_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978125\n"
     ]
    }
   ],
   "source": [
    "review_train, review_test, label_train, label_test = train_test_split(result['pos'],result['Labels'], test_size=0.2,random_state=1)\n",
    "\n",
    "X_test_tf = tf_vect.transform(review_test)\n",
    "pred = clf.predict(X_test_tf)\n",
    "print(metrics.accuracy_score(label_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   deceptive       0.89      0.89      0.89       144\n",
      "       truth       0.91      0.91      0.91       176\n",
      "\n",
      "    accuracy                           0.90       320\n",
      "   macro avg       0.90      0.90      0.90       320\n",
      "weighted avg       0.90      0.90      0.90       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(label_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96875\n"
     ]
    }
   ],
   "source": [
    "review_train, review_test, label_train, label_test = train_test_split(result['pos'],result['Labels'], test_size=0.2,random_state=10)\n",
    "X_test_tf = tf_vect.transform(review_test)\n",
    "pred = clf.predict(X_test_tf)\n",
    "print(metrics.accuracy_score(label_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98125\n"
     ]
    }
   ],
   "source": [
    "review_train, review_test, label_train, label_test = train_test_split(result['pos'],result['Labels'], test_size=0.2,random_state=42)\n",
    "X_test_tf = tf_vect.transform(review_test)\n",
    "pred = clf.predict(X_test_tf)\n",
    "print(metrics.accuracy_score(label_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['deceptive'], dtype=object)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_string(s):\n",
    "    X_test_tf = tf_vect.transform([s])\n",
    "    y_predict = clf.predict(X_test_tf)\n",
    "    return y_predict\n",
    "test_string(\"If you miss rudeness If you have nowhere to throw your money away That way ! Feel at home They'll make you look like an idiot Enjoy !!!!  \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['deceptive'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string(\"If you miss rudeness If you have nowhere to throw your money away That way ! Feel at home They'll make you look like an idiot Enjoy !!!!  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['deceptive'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>desc</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shoreham</td>\n",
       "      <td>Booking messed up</td>\n",
       "      <td>The hotel messed up on the booking and then wa...</td>\n",
       "      <td>sarahpustilnik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shoreham</td>\n",
       "      <td>Couples 1 Night Stay</td>\n",
       "      <td>The room was ok, a little smaller than expecte...</td>\n",
       "      <td>Alive1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shoreham</td>\n",
       "      <td>Great stay</td>\n",
       "      <td>Staff was great and helpful with everything. T...</td>\n",
       "      <td>britpaco24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shoreham</td>\n",
       "      <td>Great Staff, Cleanliness could have been better!</td>\n",
       "      <td>Amazing staff, they were extremely helpful and...</td>\n",
       "      <td>mrsrush0109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shoreham</td>\n",
       "      <td>Wow, there is just no way</td>\n",
       "      <td>There is no way this is a four star accommodat...</td>\n",
       "      <td>Cruiser550427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name                                             title  \\\n",
       "0  Shoreham                                 Booking messed up   \n",
       "1  Shoreham                              Couples 1 Night Stay   \n",
       "2  Shoreham                                        Great stay   \n",
       "3  Shoreham  Great Staff, Cleanliness could have been better!   \n",
       "4  Shoreham                         Wow, there is just no way   \n",
       "\n",
       "                                                desc            user  \n",
       "0  The hotel messed up on the booking and then wa...  sarahpustilnik  \n",
       "1  The room was ok, a little smaller than expecte...       Alive1017  \n",
       "2  Staff was great and helpful with everything. T...      britpaco24  \n",
       "3  Amazing staff, they were extremely helpful and...     mrsrush0109  \n",
       "4  There is no way this is a four star accommodat...   Cruiser550427  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_reviews = pd.read_excel (r'C:\\\\Users\\\\ilans\\\\Documents\\\\Studies\\\\Semester 5\\\\Final Project\\\\op_spam_v1.4\\\\hotelReviewsAll.xlsx')\n",
    "new_reviews.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "to_test=[]\n",
    "NR=new_reviews['desc']\n",
    "test_results=[]\n",
    "for i in NR:\n",
    "    X_test_tf = tf_vect.transform([i])\n",
    "    y_predict = clf.predict(X_test_tf)\n",
    "    test_results.append(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUE_TEST=[]\n",
    "for i in test_results:\n",
    "    TRUE_TEST.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reviews['reliability']=TRUE_TEST\n",
    "new_reviews.to_excel('C:\\\\Users\\\\ilans\\\\Documents\\\\Studies\\\\Semester 5\\\\Final Project\\\\op_spam_v1.4\\\\hotelReviewsAllAnalyzed.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33084\n",
      "7124\n"
     ]
    }
   ],
   "source": [
    "cnt_truth=0\n",
    "cnt_deceptive=0\n",
    "cnt_error=0\n",
    "for i in TRUE_TEST:\n",
    "    if i=='truth':\n",
    "        cnt_truth+=1\n",
    "    if i=='deceptive':\n",
    "        cnt_deceptive+=1\n",
    "print(cnt_truth)\n",
    "print(cnt_deceptive)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['truth'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string(\"dsadfd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['truth'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string(revs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-222-0f5b3d4293cd>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-222-0f5b3d4293cd>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    text = word_tokenize(\"And now for something completely different\")nltk.pos_tag(text)\u001b[0m\n\u001b[1;37m                                                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "text = word_tokenize(\"And now for something completely different\")nltk.pos_tag(text)\n",
    "doc = nltk(text)\n",
    "\n",
    "# Obtain tags using pos_tag\n",
    "print(\"The pos tags of the given text:\")\n",
    "for tok in doc:\n",
    "    print((tok.text, tok.tag_))\n",
    "\n",
    "print(\"*\"*20)          \n",
    "print(\"The universal pos tags of the given text\")\n",
    "print(\"*\"*20) \n",
    "for tok in doc:\n",
    "    print((tok.text, tok.pos_))\n",
    "\n",
    "print(\"*\"*20)\n",
    "print(\"The extracted noun phrases is: \")\n",
    "print(\"*\"*20) \n",
    "for noun_chunk in doc.noun_chunks:\n",
    "    print(noun_chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[165   3]\n",
      " [  3 149]]\n"
     ]
    }
   ],
   "source": [
    "print (confusion_matrix(label_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
